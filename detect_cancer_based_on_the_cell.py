# -*- coding: utf-8 -*-
"""Detect Cancer based on the cell

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FW7ByE3dyYXZKoKKhZFrenrAW8Nog9Gu
"""

## Breast cancer is the most common cancer amongst the women in the world. It accounts for 25 percent of all cancer and affects millions of people yearly alone. It starts with when cells in breast begin to grow out of control.These cells usually forms a tumor that can be seen via Xray.
## The early diagonosis increases the chance of survival. 
## The key challenges against it’s detection is how to classify tumors into malignant (cancerous) or benign(non cancerous)
## In this study, my task is to classify tumors into malignant (cancerous) or benign (non-cancerous) using features obtained from several cell images.

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# % matplotlib inline 

from sklearn.datasets import load_breast_cancer
cancer = load_breast_cancer()

cancer = pd.DataFrame(np.c_[cancer['data'],cancer['target']],columns = np.append(cancer['feature_names'],['target']))

print(cancer.head(10))

cancer.columns

## Lets visualize the relationship between our features
sns.pairplot(cancer, hue = 'target', vars = ['mean radius', 'mean texture', 'mean perimeter', 'mean area',
       'mean smoothness'])

# Lets Check the correlation between our feautures
plt.figure(figsize=(20,12))
sns.heatmap(cancer.corr(), annot = True)

## The modeling process and introduction to classification modelling: Support Vector Machines(SVM).
## SVM is a binary linear classification whose decision boundaries are explicity constructed to minimize generalization error.
## SVM will classify:"If classification of observation is linearly separable ", SVM fits the decision boundaries that will define by the largest margins between the closest point for each classes. This is commonly called the "maxiumum margins hyperplane".

## Lets train the model
X = cancer.drop('target',axis=1)
X.head()

y = cancer['target']
y.head()

from sklearn.model_selection import train_test_split

X_train, X_test, Y_train, Y_test = train_test_split(X,y,test_size = 0.2, random_state = 20)

print("The size of our training X (input_feautures) is ", X_train.shape)
print("\n")
print("The size of our testing X (input_feautures) is ", X_test.shape)
print("\n")
print("The size of our testing X (input_feautures) is ", Y_train.shape)
print("\n")
print("The size of our testing X (input_feautures) is ", Y_test.shape)
print("\n")

from sklearn.svm import SVC

svc_model = SVC()

svc_model.fit(X_train,Y_train)

y_predict = svc_model.predict(X_test)

## Lets create the confusion matrix for our classifier performance on the test dataset

from sklearn.metrics import classification_report, confusion_matrix

cm = np.array(confusion_matrix(Y_test,y_predict, labels=[1,0]))
confusion = pd.DataFrame(cm, index=["is_cancer","is_healthy"],
                        columns = ['predicter_cancer','predicted_healthy'])
confusion

sns.heatmap(confusion,annot = True)

print(classification_report(Y_test,y_predict))

X_train_min = X_train.min()
X_train_min

X_train_max = X_train.max()
X_train_max

X_train_range = X_train_max-X_train_min
X_train_range

## This took us through the journey of explaining what “modeling” means in Data Science, difference between model prediction and inference, introduction to Support Vector Machine (SVM), advantages and disadvantages of SVM, training an SVM model to make accurate breast cancer classifications, improving the performance of an SVM model, and testing model accuracy using Confusion Matrix.

